{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Jab2DUXez4z1kx-o-Btc9jKPcoslob_t",
      "authorship_tag": "ABX9TyMJxpzCdbt7M39Z5sHebfxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jarcos09/Tareas/blob/main/ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéì **Inteligencia Artificial Aplicada**\n",
        "\n",
        "## ü§ñ **An√°lisis de grandes vol√∫menes de datos (Gpo 10)**\n",
        "\n",
        "### üèõÔ∏è Tecnol√≥gico de Monterrey\n",
        "\n",
        "#### üë®‚Äçüè´ **Profesor titular :** Dr. Iv√°n Olmos Pineda\n",
        "#### üë©‚Äçüè´ **Profesor asistente :** Ver√≥nica Sandra Guzm√°n de Valle\n",
        "\n",
        "### üìä **Actividad 3 | Aprendizaje supervisado y no supervisado**\n",
        "\n",
        "#### üìÖ **25 de mayo de 2025**\n",
        "\n",
        "üßë‚Äçüíª **A01795941 :** Juan Carlos P√©rez Nava\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XLo2RHbqcPHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aprendizaje autom√°tico**\n",
        "\n",
        "En el √°mbito del aprendizaje autom√°tico, existen tres enfoques principales dentro del proceso de Machine Learning: el aprendizaje supervisado, el aprendizaje no supervisado y el aprendizaje por refuerzo.\n",
        "\n",
        "# Aprendizaje supervisado\n",
        "\n",
        "En el aprendizaje supervisado, el modelo se entrena con un conjunto de datos etiquetados, donde cada ejemplo de entrada est√° asociado a una salida deseada o etiqueta. A trav√©s de este proceso, el modelo aprende a identificar patrones y a realizar predicciones sobre nuevos datos con caracter√≠sticas similares. Este tipo de aprendizaje es ampliamente utilizado en aplicaciones como el reconocimiento de im√°genes, el procesamiento de lenguaje natural y los sistemas de recomendaci√≥n.\n",
        "\n",
        "El aprendizaje supervisado se emplea principalmente en problemas de clasificaci√≥n y regresi√≥n. En la clasificaci√≥n, el objetivo es asignar una categor√≠a a cada instancia de entrada, como ocurre en el filtrado de correos electr√≥nicos entre \"spam\" y \"no spam\" o en la clasificaci√≥n de im√°genes de acuerdo con su contenido. Por otro lado, en la regresi√≥n, el prop√≥sito es predecir un valor num√©rico en funci√≥n de los datos disponibles, lo que resulta √∫til en tareas como la predicci√≥n del precio de una vivienda, la estimaci√≥n de ventas futuras o el an√°lisis de tendencias econ√≥micas.\n",
        "\n",
        "**Algoritmos representativos**\n",
        "\n",
        "* *Regresi√≥n Lineal* : Predice valores num√©ricos bas√°ndose en relaciones lineales entre variables.\n",
        "* *Regresi√≥n Log√≠stica* : Algoritmo utilizado para clasificaci√≥n binaria, que modela la probabilidad de que una instancia pertenezca a una de dos categor√≠as mediante una funci√≥n log√≠stica.\n",
        "* *√Årboles de Decisi√≥n* : Modelos que utilizan una estructura jer√°rquica basada en reglas para dividir los datos seg√∫n sus caracter√≠sticas. Cada nodo representa una decisi√≥n basada en un atributo, y las hojas corresponden a las posibles clasificaciones o predicciones.\n",
        "* *Random Forest* : Algoritmo basado en un conjunto de √°rboles de decisi√≥n, donde cada √°rbol contribuye a la predicci√≥n final mediante un proceso de votaci√≥n o promedio.\n",
        "* *Support Vector Machines (SVM)* : Algoritmo que identifica un hiperplano √≥ptimo para separar las diferentes clases dentro de un espacio de caracter√≠sticas.\n",
        "* *Redes Neuronales* : Modelos computacionales inspirados en el funcionamiento de las neuronas biol√≥gicas, dise√±ados para resolver tareas complejas mediante el aprendizaje autom√°tico y la adaptaci√≥n de patrones en los datos.\n",
        "\n",
        "\n",
        "`PySpark` ofrece una amplia variedad de algoritmos de aprendizaje supervisado a trav√©s de `MLlib`, dise√±ados para resolver problemas de clasificaci√≥n y regresi√≥n en entornos de procesamiento distribuido. Algunos de los algoritmos m√°s representativos incluyen:\n",
        "\n",
        "* *LinearRegression* : Modelo utilizado para predecir valores num√©ricos.\n",
        "* *LogisticRegression* : Algoritmo de clasificaci√≥n binaria basado en la funci√≥n log√≠stica.\n",
        "* *DecisionTreeClassifier* : √Årboles de decisi√≥n que segmentan los datos seg√∫n criterios espec√≠ficos para realizar clasificaciones.\n",
        "* *RandomForestClassifier* : Conjunto de √°rboles de decisi√≥n que mejora la precisi√≥n y reduce el sobreajuste mediante el aprendizaje en m√∫ltiples subconjuntos de datos.\n",
        "* *GBTClassifier (Gradient Boosted Trees)* : Algoritmo basado en √°rboles de decisi√≥n potenciados mediante el m√©todo de boosting.\n",
        "*\t*MultilayerPerceptronClassifier (Redes neuronales)* : Algoritmo de\n",
        "aprendizaje supervisado basado en redes neuronales multicapa.\n",
        "\n",
        "# Aprendizaje no supervisado\n",
        "\n",
        "El aprendizaje no supervisado es una forma de aprendizaje autom√°tico que trabaja con datos sin etiquetas, es decir, sin respuestas conocidas de antemano. A diferencia del aprendizaje supervisado, donde el modelo aprende a partir de ejemplos con resultados correctos, en el aprendizaje no supervisado el **objetivo es descubrir patrones, estructuras o relaciones** dentro de los datos sin una gu√≠a espec√≠fica.\n",
        "\n",
        "Este enfoque es especialmente √∫til cuando se trabaja con conjuntos de datos donde no se conoce la estructura ni la relaci√≥n entre las variables. Una de las t√©cnicas m√°s utilizadas en el aprendizaje no supervisado es el agrupamiento (clustering), que organiza los datos en grupos seg√∫n sus similitudes. Esto ayuda a identificar patrones ocultos y facilita su an√°lisis.\n",
        "\n",
        "**Algoritmos representativos**\n",
        "\n",
        "* *K-Means* : Agrupa los datos en k grupos seg√∫n sus similitudes.\n",
        "* *Gaussian Mixture Model (GMM)* : Modelo que asigna probabilidades a cada punto para determinar a qu√© grupo pertenece.\n",
        "* *Hierarchical Clustering* : Crea una estructura de grupos organizados en distintos niveles, como un √°rbol.\n",
        "* *DBSCAN* : Encuentra grupos de datos con diferentes densidades, permitiendo detectar patrones en conjuntos m√°s dispersos.\n",
        "* *PCA (An√°lisis de Componentes Principales)* : Reduce la cantidad de variables en los datos, conservando la informaci√≥n m√°s importante para facilitar su an√°lisis.\n",
        "\n",
        "`PySpark MLlib` ofrece varios algoritmos de aprendizaje no supervisado, que ayudan a encontrar patrones en los datos sin necesidad de etiquetas. Algunos de los m√°s usados son:\n",
        "\n",
        "* *KMeans* : Agrupa los datos en varios grupos seg√∫n sus similitudes.\n",
        "* *GaussianMixture* : Usa probabilidades para asignar cada dato a un grupo.\n",
        "* *BisectingKMeans* : Variante de K-Means que divide los datos de manera m√°s organizada.\n",
        "* *PowerIterationClustering* : M√©todo que descubre relaciones en los datos mediante c√°lculos repetitivos.\n",
        "* *PCA (An√°lisis de Componentes Principales)* : Reduce la cantidad de variables para hacer m√°s f√°cil el an√°lisis de datos complejos.\n",
        "\n",
        "# Aprendizaje por refuerzo\n",
        "\n",
        "El aprendizaje por refuerzo es un enfoque dentro del aprendizaje autom√°tico en el que un agente interact√∫a con un entorno din√°mico y aprende a tomar decisiones. B√°sicamente, prueba diferentes acciones, recibe retroalimentaci√≥n en forma de recompensas o penalizaciones y ajusta su comportamiento para mejorar con el tiempo.\n",
        "\n"
      ],
      "metadata": {
        "id": "cAcY6f52II4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# M√≥dulos del sistema para manejo de rutas\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Definici√≥n del path para incluir una librer√≠a personalizada\n",
        "module_path = os.path.abspath(os.path.join('proyectos/librerias'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "# Importaci√≥n de m√≥dulos gr√°ficos personalizados\n",
        "from graficas import *\n",
        "\n",
        "# Importaci√≥n de PySpark para manipulaci√≥n y an√°lisis de datos\n",
        "from pyspark.sql import (\n",
        "    SparkSession, DataFrame\n",
        ")\n",
        "from pyspark.sql.types import (\n",
        "    StructType, StructField, StringType, IntegerType, DoubleType\n",
        ")\n",
        "from pyspark.sql.functions import (\n",
        "    col, sum, avg, lit, count, when, format_number, round, rand\n",
        ")\n",
        "from pyspark.ml.feature import (\n",
        "    StringIndexer, OneHotEncoder, QuantileDiscretizer,\n",
        "    VectorAssembler, StandardScaler, Imputer\n",
        ")\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
        "\n",
        "from pyspark.ml.clustering import KMeans, GaussianMixture\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "# Importaci√≥n de librer√≠as para visualizaci√≥n\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Librer√≠a para la integraci√≥n con Kaggle\n",
        "import kagglehub\n",
        "\n",
        "# Manipulaci√≥n de datos con Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Funciones de programaci√≥n funcional\n",
        "from functools import reduce"
      ],
      "metadata": {
        "id": "lNK_005tHX9o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"sobhanmoosavi/us-accidents\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7RDNtCfV_j8",
        "outputId": "5e455f2a-fa61-4edc-f121-b4b261aeca4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /home/jarcos/.cache/kagglehub/datasets/sobhanmoosavi/us-accidents/versions/13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creaci√≥n de una sesi√≥n de Spark\n",
        "# Se configura el modo \"local[*]\" para usar todos los n√∫cleos disponibles en la m√°quina\n",
        "# Se asigna un nombre a la aplicaci√≥n y se configuran los l√≠mites de memoria para el driver y los ejecutores\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"CargarCSV\").config(\"spark.driver.memory\", \"40g\").config(\"spark.executor.memory\", \"20g\").getOrCreate()\n",
        "df_accident = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(path)\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzhCy58rgjX1",
        "outputId": "a67dd34e-6324-4496-db5f-7a0fbcb4d876"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "25/05/24 22:04:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_accident.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97uEFSF5t4A0",
        "outputId": "e7a6b29a-420c-485a-ffd1-5de37066443a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
            "| ID| Source|Severity|         Start_Time|           End_Time|        Start_Lat|         Start_Lng|End_Lat|End_Lng|Distance(mi)|         Description|              Street|        City|    County|State|   Zipcode|Country|  Timezone|Airport_Code|  Weather_Timestamp|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Precipitation(in)|Weather_Condition|Amenity| Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station| Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|\n",
            "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
            "|A-1|Source2|       3|2016-02-08 05:46:00|2016-02-08 11:00:00|        39.865147|        -84.058723|   NULL|   NULL|        0.01|Right lane blocke...|              I-70 E|      Dayton|Montgomery|   OH|     45424|     US|US/Eastern|        KFFO|2016-02-08 05:58:00|          36.9|         NULL|       91.0|       29.68|          10.0|          Calm|           NULL|             0.02|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                Night|\n",
            "|A-2|Source2|       2|2016-02-08 06:07:59|2016-02-08 06:37:59|39.92805900000001|        -82.831184|   NULL|   NULL|        0.01|Accident on Brice...|            Brice Rd|Reynoldsburg|  Franklin|   OH|43068-3402|     US|US/Eastern|        KCMH|2016-02-08 05:51:00|          37.9|         NULL|      100.0|       29.65|          10.0|          Calm|           NULL|              0.0|       Light Rain|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|         Night|            Night|                  Day|\n",
            "|A-3|Source2|       2|2016-02-08 06:49:27|2016-02-08 07:19:27|        39.063148|        -84.032608|   NULL|   NULL|        0.01|Accident on OH-32...|      State Route 32|Williamsburg|  Clermont|   OH|     45176|     US|US/Eastern|        KI69|2016-02-08 06:56:00|          36.0|         33.3|      100.0|       29.67|          10.0|            SW|            3.5|             NULL|         Overcast|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|         Night|         Night|              Day|                  Day|\n",
            "|A-4|Source2|       3|2016-02-08 07:23:34|2016-02-08 07:53:34|        39.747753|-84.20558199999998|   NULL|   NULL|        0.01|Accident on I-75 ...|              I-75 S|      Dayton|Montgomery|   OH|     45417|     US|US/Eastern|        KDAY|2016-02-08 07:38:00|          35.1|         31.0|       96.0|       29.64|           9.0|            SW|            4.6|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|         false|       false|         Night|           Day|              Day|                  Day|\n",
            "|A-5|Source2|       2|2016-02-08 07:39:07|2016-02-08 08:09:07|        39.627781|        -84.188354|   NULL|   NULL|        0.01|Accident on McEwe...|Miamisburg Center...|      Dayton|Montgomery|   OH|     45459|     US|US/Eastern|        KMGY|2016-02-08 07:53:00|          36.0|         33.3|       89.0|       29.65|           6.0|            SW|            3.5|             NULL|    Mostly Cloudy|  false|false|   false|   false|   false|  false|  false|     false|  false|false|          false|          true|       false|           Day|           Day|              Day|                  Day|\n",
            "+---+-------+--------+-------------------+-------------------+-----------------+------------------+-------+-------+------------+--------------------+--------------------+------------+----------+-----+----------+-------+----------+------------+-------------------+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+-----+--------+--------+--------+-------+-------+----------+-------+-----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecci√≥n de los datos\n",
        "\n",
        "El conjunto de datos se particiona tomando en cuenta las condiciones clim√°ticas y la severidad del accidente, dividi√©ndolo en m√∫ltiples subconjuntos seg√∫n combinaciones espec√≠ficas de estas caracter√≠sticas. Esta misma partici√≥n fue la propuesta en el ejercicio anterior."
      ],
      "metadata": {
        "id": "BZDsQ0zuhJRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n de las columnas clave que ser√°n utilizadas para el an√°lisis y particionamiento\n",
        "columnas_clave = [\n",
        "    \"ID\", \"Weather_Condition\",\"Precipitation(in)\",\"Severity\", \"City\", \"State\",\n",
        "    \"Temperature(F)\", \"Humidity(%)\", \"Visibility(mi)\",\"Wind_Direction\",\"Wind_Speed(mph)\",\"Crossing\",\"Junction\",\"Railway\",\n",
        "    \"Roundabout\",\"Stop\",\"Sunrise_Sunset\",\"Traffic_Calming\",\"Traffic_Signal\"]\n",
        "\n",
        "total = df_accident.count()\n",
        "\n",
        "# Agrupaci√≥n de los datos por condici√≥n clim√°tica y severidad del accidente\n",
        "# Se calcula la frecuencia de cada combinaci√≥n y su proporci√≥n respecto al total de datos\n",
        "combinaciones_top = df_accident.groupBy(\"Weather_Condition\", \"Severity\") \\\n",
        "    .agg(count(\"*\").alias(\"Frecuencia\")) \\\n",
        "    .withColumn(\"Proporci√≥n\", col(\"Frecuencia\") / total) \\\n",
        "    .orderBy(col(\"Proporci√≥n\").desc())\n",
        "\n",
        "# Transformaci√≥n de la columna \"Proporci√≥n\" para expresarla en porcentaje\n",
        "combinaciones_top = combinaciones_top.withColumn(\"Frecuencia\", col(\"Frecuencia\"))  \\\n",
        "    .withColumn(\"Proporci√≥n\", col(\"Proporci√≥n\")*100)\n",
        "\n",
        "# Escritura del DataFrame en formato Parquet, particionando por las columnas \"Weather_Condition\" y \"Severity\"\n",
        "df_particionada = df_accident.select(columnas_clave)\n",
        "df_particionada.write.mode(\"overwrite\").partitionBy(\"Weather_Condition\",\"Severity\").parquet(\"us_accidents_partitioned\")\n",
        "\n",
        "combinaciones_top.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90X1Pa19yCZP",
        "outputId": "ab97222b-621a-40eb-deaf-b8681978f600"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------+----------+------------------+\n",
            "|Weather_Condition|Severity|Frecuencia|Proporci√≥n        |\n",
            "+-----------------+--------+----------+------------------+\n",
            "|Fair             |2       |2226576   |28.810332392473782|\n",
            "|Mostly Cloudy    |2       |792735    |10.25743511523869 |\n",
            "|Cloudy           |2       |692929    |8.966015449005317 |\n",
            "|Partly Cloudy    |2       |548760    |7.1005696655734685|\n",
            "|Clear            |2       |536971    |6.948028270815386 |\n",
            "|Light Rain       |2       |270162    |3.495706870017238 |\n",
            "|Overcast         |2       |248938    |3.22108319011686  |\n",
            "|Clear            |3       |244956    |3.1695589018882835|\n",
            "|Fair             |3       |240084    |3.1065186376367455|\n",
            "|Mostly Cloudy    |3       |189229    |2.4484905919651614|\n",
            "+-----------------+--------+----------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definici√≥n del umbral m√≠nimo de registros para considerar una partici√≥n\n",
        "max_reg = 2000\n",
        "\n",
        "# Filtrado de combinaciones donde la frecuencia es mayor o igual al umbral definido\n",
        "combinaciones_filtradas = combinaciones_top.filter(col(\"Frecuencia\") >= max_reg)\n",
        "\n",
        "# Recolecci√≥n de las combinaciones filtradas en una lista para su uso posterior\n",
        "particiones = combinaciones_filtradas.select(\"Weather_Condition\", \"Severity\").collect()\n",
        "\n",
        "print(f'‚úÖ Se identificaron \\033[32m\\033[1m{len(particiones)}\\033[0m particiones que contienen m√°s de \\033[36m{max_reg}\\033[0m registros.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7nfphRPbPN3",
        "outputId": "e6c7cc3f-c2f7-4333-c7ac-5e9d5d0dc1e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Se identificaron \u001b[32m\u001b[1m77\u001b[0m particiones que contienen m√°s de \u001b[36m2000\u001b[0m registros.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Stage 10:===================================================>    (21 + 2) / 23]\r\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# N√∫mero de muestras a extraer por partici√≥n\n",
        "muestras = 2000\n",
        "contador_total = 0\n",
        "semilla = 450\n",
        "\n",
        "# Crear un DataFrame vac√≠o con la misma estructura que df_particionada\n",
        "df_muestras = spark.createDataFrame([], df_particionada.schema)\n",
        "lista_muestras = []\n",
        "\n",
        "for particion in particiones:\n",
        "\n",
        "    contador_total += 1\n",
        "    weather = particion[\"Weather_Condition\"]\n",
        "    severity = particion[\"Severity\"]\n",
        "\n",
        "    print(f\"Extrayendo Partici√≥n #\\033[32m\\033[1m{contador_total:03}\\033[0m | üå¶ Weather: \\033[1;36m{weather}\\033[0m | ‚ö† Severity: \\033[1;36m{severity}\\033[0m\")\n",
        "\n",
        "    # Filtrar los registros que corresponden a la condici√≥n clim√°tica y severidad\n",
        "    df_filtrada = df_particionada.filter((col(\"Weather_Condition\") == weather) & (col(\"Severity\") == severity))\n",
        "\n",
        "    # Ordenar aleatoriamente los registros y limitar la cantidad de muestras extra√≠das\n",
        "    df_rand = df_filtrada.orderBy(rand(semilla)).limit(muestras)\n",
        "\n",
        "    lista_muestras.append(df_rand)\n",
        "\n",
        "df_muestras = lista_muestras[0]\n",
        "\n",
        "# Unir todas las muestras en un solo DataFrame\n",
        "for df in lista_muestras[1:]:\n",
        "    df_muestras = df_muestras.union(df)\n",
        "\n",
        "# Se reduce el n√∫mero de particiones para mejorar la eficiencia en el procesamiento\n",
        "df_muestras = df_muestras.persist().coalesce(8)\n",
        "\n",
        "contador_total = df_muestras.count()\n",
        "print(f\"Total de registros obtenidos en la muestra: \\033[32m\\033[1m{contador_total}\\033[0m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0ZXtzjReRcH",
        "outputId": "2a256167-1322-482c-d2c4-c3bdfeee9137"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m001\u001b[0m | üå¶ Weather: \u001b[1;36mFair\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m002\u001b[0m | üå¶ Weather: \u001b[1;36mMostly Cloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m003\u001b[0m | üå¶ Weather: \u001b[1;36mCloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m004\u001b[0m | üå¶ Weather: \u001b[1;36mPartly Cloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m005\u001b[0m | üå¶ Weather: \u001b[1;36mClear\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m006\u001b[0m | üå¶ Weather: \u001b[1;36mLight Rain\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m007\u001b[0m | üå¶ Weather: \u001b[1;36mOvercast\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m008\u001b[0m | üå¶ Weather: \u001b[1;36mClear\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m009\u001b[0m | üå¶ Weather: \u001b[1;36mFair\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m010\u001b[0m | üå¶ Weather: \u001b[1;36mMostly Cloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m011\u001b[0m | üå¶ Weather: \u001b[1;36mNone\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m012\u001b[0m | üå¶ Weather: \u001b[1;36mScattered Clouds\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m013\u001b[0m | üå¶ Weather: \u001b[1;36mPartly Cloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m014\u001b[0m | üå¶ Weather: \u001b[1;36mOvercast\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m015\u001b[0m | üå¶ Weather: \u001b[1;36mLight Snow\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m016\u001b[0m | üå¶ Weather: \u001b[1;36mCloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m017\u001b[0m | üå¶ Weather: \u001b[1;36mFog\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m018\u001b[0m | üå¶ Weather: \u001b[1;36mLight Rain\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m019\u001b[0m | üå¶ Weather: \u001b[1;36mScattered Clouds\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m020\u001b[0m | üå¶ Weather: \u001b[1;36mRain\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m021\u001b[0m | üå¶ Weather: \u001b[1;36mHaze\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m022\u001b[0m | üå¶ Weather: \u001b[1;36mFair\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m023\u001b[0m | üå¶ Weather: \u001b[1;36mFair\u001b[0m | ‚ö† Severity: \u001b[1;36m1\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m024\u001b[0m | üå¶ Weather: \u001b[1;36mFair / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m025\u001b[0m | üå¶ Weather: \u001b[1;36mNone\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m026\u001b[0m | üå¶ Weather: \u001b[1;36mClear\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m027\u001b[0m | üå¶ Weather: \u001b[1;36mHeavy Rain\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m028\u001b[0m | üå¶ Weather: \u001b[1;36mMostly Cloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m029\u001b[0m | üå¶ Weather: \u001b[1;36mCloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m030\u001b[0m | üå¶ Weather: \u001b[1;36mLight Snow\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m031\u001b[0m | üå¶ Weather: \u001b[1;36mRain\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m032\u001b[0m | üå¶ Weather: \u001b[1;36mLight Drizzle\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m033\u001b[0m | üå¶ Weather: \u001b[1;36mPartly Cloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m034\u001b[0m | üå¶ Weather: \u001b[1;36mThunder in the Vicinity\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m035\u001b[0m | üå¶ Weather: \u001b[1;36mCloudy / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m036\u001b[0m | üå¶ Weather: \u001b[1;36mHaze\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m037\u001b[0m | üå¶ Weather: \u001b[1;36mOvercast\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m038\u001b[0m | üå¶ Weather: \u001b[1;36mMostly Cloudy / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m039\u001b[0m | üå¶ Weather: \u001b[1;36mT-Storm\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m040\u001b[0m | üå¶ Weather: \u001b[1;36mSnow\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m041\u001b[0m | üå¶ Weather: \u001b[1;36mThunder\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m042\u001b[0m | üå¶ Weather: \u001b[1;36mLight Rain with Thunder\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m043\u001b[0m | üå¶ Weather: \u001b[1;36mMostly Cloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m1\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m044\u001b[0m | üå¶ Weather: \u001b[1;36mSmoke\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m045\u001b[0m | üå¶ Weather: \u001b[1;36mWintry Mix\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m046\u001b[0m | üå¶ Weather: \u001b[1;36mFog\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m047\u001b[0m | üå¶ Weather: \u001b[1;36mLight Rain\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m048\u001b[0m | üå¶ Weather: \u001b[1;36mPartly Cloudy / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m049\u001b[0m | üå¶ Weather: \u001b[1;36mCloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m1\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m050\u001b[0m | üå¶ Weather: \u001b[1;36mHeavy T-Storm\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m051\u001b[0m | üå¶ Weather: \u001b[1;36mNone\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m052\u001b[0m | üå¶ Weather: \u001b[1;36mHeavy Rain\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m053\u001b[0m | üå¶ Weather: \u001b[1;36mPartly Cloudy\u001b[0m | ‚ö† Severity: \u001b[1;36m1\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m054\u001b[0m | üå¶ Weather: \u001b[1;36mLight Rain / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m055\u001b[0m | üå¶ Weather: \u001b[1;36mLight Snow / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m056\u001b[0m | üå¶ Weather: \u001b[1;36mScattered Clouds\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m057\u001b[0m | üå¶ Weather: \u001b[1;36mLight Snow\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m058\u001b[0m | üå¶ Weather: \u001b[1;36mLight Drizzle\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m059\u001b[0m | üå¶ Weather: \u001b[1;36mHeavy Snow\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m060\u001b[0m | üå¶ Weather: \u001b[1;36mDrizzle\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m061\u001b[0m | üå¶ Weather: \u001b[1;36mFair / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m062\u001b[0m | üå¶ Weather: \u001b[1;36mPatches of Fog\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m063\u001b[0m | üå¶ Weather: \u001b[1;36mN/A Precipitation\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m064\u001b[0m | üå¶ Weather: \u001b[1;36mLight Thunderstorms and Rain\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m065\u001b[0m | üå¶ Weather: \u001b[1;36mT-Storm\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m066\u001b[0m | üå¶ Weather: \u001b[1;36mFog\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m067\u001b[0m | üå¶ Weather: \u001b[1;36mThunderstorm\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m068\u001b[0m | üå¶ Weather: \u001b[1;36mMist\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m069\u001b[0m | üå¶ Weather: \u001b[1;36mShallow Fog\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m070\u001b[0m | üå¶ Weather: \u001b[1;36mLight Rain with Thunder\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m071\u001b[0m | üå¶ Weather: \u001b[1;36mSnow\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m072\u001b[0m | üå¶ Weather: \u001b[1;36mLight Rain\u001b[0m | ‚ö† Severity: \u001b[1;36m1\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m073\u001b[0m | üå¶ Weather: \u001b[1;36mMostly Cloudy / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m074\u001b[0m | üå¶ Weather: \u001b[1;36mLight Freezing Rain\u001b[0m | ‚ö† Severity: \u001b[1;36m2\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m075\u001b[0m | üå¶ Weather: \u001b[1;36mThunder in the Vicinity\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m076\u001b[0m | üå¶ Weather: \u001b[1;36mCloudy / Windy\u001b[0m | ‚ö† Severity: \u001b[1;36m3\u001b[0m\n",
            "Extrayendo Partici√≥n #\u001b[32m\u001b[1m077\u001b[0m | üå¶ Weather: \u001b[1;36mRain\u001b[0m | ‚ö† Severity: \u001b[1;36m4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros obtenidos en la muestra: \u001b[32m\u001b[1m148000\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparaci√≥n de los datos"
      ],
      "metadata": {
        "id": "tzMcfXbtGIPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para obtener un resumen de valores nulos en un DataFrame de PySpark\n",
        "def obten_nulos(particion):\n",
        "\n",
        "  print(f\"üìä Total de filas en la partici√≥n: {particion.count()}\")\n",
        "  print(f\"üóÇÔ∏è N√∫mero de columnas en la partici√≥n: {len(particion.columns)}\")\n",
        "\n",
        "  info_nulos = {}\n",
        "  cols_nulos = {}\n",
        "  total_rows = particion.count()\n",
        "  registros_totales = particion.count()\n",
        "\n",
        "  # Contar valores nulos por columna y almacenarlos en un DataFrame temporal\n",
        "\n",
        "  cols_nulos = particion.select(\n",
        "    [sum(col(c).isNull().cast(\"int\")).alias(c) for c in particion.columns]\n",
        "    )\n",
        "\n",
        "  # Convertir los resultados en un diccionario para f√°cil acceso\n",
        "  info_nulos = {c: cols_nulos.select(c).collect()[0][0] for c in particion.columns}\n",
        "\n",
        "  # Filtrar solo las columnas con valores nulos y calcular el porcentaje de nulos\n",
        "  cols_nulos = {c: {\"count\": v, \"percent\": (v / total_rows) * 100} for c, v in info_nulos.items() if v > 0}\n",
        "\n",
        "  # Validar si existen columnas con valores nulos\n",
        "  if not cols_nulos:\n",
        "        print(\"‚úÖ No existen valores nulos en la partici√≥n.\")\n",
        "        return\n",
        "\n",
        "  # Crear una lista con los resultados para construir un DataFrame\n",
        "  listado = [(key, value['count'], value['percent']) for key, value in cols_nulos.items()]\n",
        "\n",
        "  # Definir el esquema del DataFrame para almacenar el resumen de valores nulos\n",
        "  schema = StructType([\n",
        "    StructField(\"Columna\", StringType(), True),\n",
        "    StructField(\"Total de nulos\", IntegerType(), True),\n",
        "    StructField(\"Porcentaje\", DoubleType(), True)\n",
        "  ])\n",
        "\n",
        "  df_resumen_nulos = spark.createDataFrame(listado, schema=schema)\n",
        "\n",
        "  for col_name in [c for c, t in df_resumen_nulos.dtypes if t == \"double\"]:\n",
        "      df_resumen_nulos = df_resumen_nulos.withColumn(col_name, round(df_resumen_nulos[col_name], 2))\n",
        "\n",
        "  # Ordenar el DataFrame por el n√∫mero de valores nulos en orden descendente y mostrarlo en consola\n",
        "  df_resumen_nulos.orderBy(col(\"Total de nulos\").desc()).show(truncate=False)"
      ],
      "metadata": {
        "id": "z3od6x_V7aP-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci√≥n para imputar valores faltantes en una partici√≥n del conjunto de datos\n",
        "def imputacion_valores(particion):\n",
        "    print(\"‚úÖ Se realiza la imputaci√≥n utilizando los siguientes valores:\\n\")\n",
        "\n",
        "    # Obtener las modas (valores m√°s frecuentes) de las variables categ√≥ricas\n",
        "    moda_Weather = particion.groupBy(\"Weather_Condition\").count().orderBy(col(\"count\").desc()).first()[\"Weather_Condition\"]\n",
        "    moda_City = particion.groupBy(\"City\").count().orderBy(col(\"count\").desc()).first()[\"City\"]\n",
        "    moda_Sunset = particion.groupBy(\"Sunrise_Sunset\").count().orderBy(col(\"count\").desc()).first()[\"Sunrise_Sunset\"]\n",
        "    moda_wub = particion.groupBy(\"Wind_Direction\").count().orderBy(col(\"count\").desc()).first()[\"Wind_Direction\"]\n",
        "\n",
        "    # Obtener promedios de las variables num√©ricas para imputaci√≥n\n",
        "    media_Temperature = particion.select(round(avg(col(\"Temperature(F)\")), 2).alias(\"avg_temp\")).collect()[0][0]\n",
        "    media_Humidity = particion.select(round(avg(col(\"Humidity(%)\")), 2).alias(\"avg_humidity\")).collect()[0][0]\n",
        "    media_Visibility = particion.select(round(avg(col(\"Visibility(mi)\")), 2).alias(\"avg_visibility\")).collect()[0][0]\n",
        "    media_Precipitation = particion.select(round(avg(col(\"Precipitation(in)\")), 2).alias(\"avg_precipitation\")).collect()[0][0]\n",
        "    media_Wind_Speed = particion.select(round(avg(col(\"Wind_Speed(mph)\")), 2).alias(\"avg_wind_speed\")).collect()[0][0]\n",
        "\n",
        "\n",
        "    # Imprimir valores calculados correctamente\n",
        "    print(f\"üå°Ô∏è Temperatura promedio: {media_Temperature}\")\n",
        "    print(f\"üíß Humedad promedio: {media_Humidity}\")\n",
        "    print(f\"üëÄ Visibilidad promedio: {media_Visibility}\")\n",
        "    print(f\"üåßÔ∏è Precipitaci√≥n promedio: {media_Precipitation}\")\n",
        "    print(f\"üå¨Ô∏è Velocidad del viento promedio: {media_Wind_Speed}\")\n",
        "\n",
        "    print(f\"‚òÅÔ∏è Condici√≥n meteorol√≥gica m√°s frecuente: {moda_Weather}\")\n",
        "    print(f\"üèôÔ∏è Ciudad m√°s frecuente: {moda_City}\")\n",
        "    print(f\"üåÖ Hora de atardecer m√°s frecuente: {moda_Sunset}\")\n",
        "    print(f\"üå¨Ô∏è Direcci√≥n del viento m√°s frecuente: {moda_wub}\")\n",
        "\n",
        "    # Aplicar imputaci√≥n de valores num√©ricos con la estrategia de promedio\n",
        "    imputer_num = Imputer(\n",
        "        inputCols=[\"Temperature(F)\", \"Humidity(%)\", \"Visibility(mi)\", \"Precipitation(in)\", \"Wind_Speed(mph)\"],\n",
        "        outputCols=[\"Temperature(F)\", \"Humidity(%)\", \"Visibility(mi)\", \"Precipitation(in)\", \"Wind_Speed(mph)\"]\n",
        "    ).setStrategy(\"mean\")\n",
        "\n",
        "    particion = imputer_num.fit(particion).transform(particion)\n",
        "\n",
        "    # Imputaci√≥n de valores categ√≥ricos utilizando la moda\n",
        "    particion = particion.na.fill({\n",
        "        \"Weather_Condition\": moda_Weather,\n",
        "        \"City\": moda_City,\n",
        "        \"Sunrise_Sunset\": moda_Sunset,\n",
        "        \"Wind_Direction\": moda_wub\n",
        "    })\n",
        "\n",
        "    print(\"\\nüîç Se validan nuevamente los valores nulos para corroborar la imputaci√≥n.\\n\")\n",
        "\n",
        "    obten_nulos(particion)\n",
        "\n",
        "    for col_name in [c for c, t in particion.dtypes if t == \"double\"]:\n",
        "      particion = particion.withColumn(col_name, round(particion[col_name], 1))\n",
        "\n",
        "    return particion"
      ],
      "metadata": {
        "id": "PS9ra8pQSM71"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obten_nulos(df_muestras)"
      ],
      "metadata": {
        "id": "vc-aW7WY73U0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d8186c3-17c6-40de-dfc6-924d6f610e5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Total de filas en la partici√≥n: 148000\n",
            "üóÇÔ∏è N√∫mero de columnas en la partici√≥n: 19\n",
            "+-----------------+--------------+----------+\n",
            "|Columna          |Total de nulos|Porcentaje|\n",
            "+-----------------+--------------+----------+\n",
            "|Precipitation(in)|33372         |22.55     |\n",
            "|Wind_Speed(mph)  |8679          |5.86      |\n",
            "|Humidity(%)      |1013          |0.68      |\n",
            "|Temperature(F)   |698           |0.47      |\n",
            "|Wind_Direction   |691           |0.47      |\n",
            "|Sunrise_Sunset   |537           |0.36      |\n",
            "|Visibility(mi)   |438           |0.3       |\n",
            "|City             |2             |0.0       |\n",
            "+-----------------+--------------+----------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Stage 3566:>                                                     (0 + 16) / 16]\r\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "muestra_imp = imputacion_valores(df_muestras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMiT-fWeUziL",
        "outputId": "bf14f1aa-ae05-4b49-b18e-5a7f405d5ef9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Se realiza la imputaci√≥n utilizando los siguientes valores:\n",
            "\n",
            "üå°Ô∏è Temperatura promedio: 57.41\n",
            "üíß Humedad promedio: 75.16\n",
            "üëÄ Visibilidad promedio: 7.01\n",
            "üåßÔ∏è Precipitaci√≥n promedio: 0.04\n",
            "üå¨Ô∏è Velocidad del viento promedio: 10.15\n",
            "‚òÅÔ∏è Condici√≥n meteorol√≥gica m√°s frecuente: Fair\n",
            "üèôÔ∏è Ciudad m√°s frecuente: Houston\n",
            "üåÖ Hora de atardecer m√°s frecuente: Day\n",
            "üå¨Ô∏è Direcci√≥n del viento m√°s frecuente: CALM\n",
            "\n",
            "üîç Se validan nuevamente los valores nulos para corroborar la imputaci√≥n.\n",
            "\n",
            "üìä Total de filas en la partici√≥n: 148000\n",
            "üóÇÔ∏è N√∫mero de columnas en la partici√≥n: 19\n",
            "‚úÖ No existen valores nulos en la partici√≥n.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identificaci√≥n de valores at√≠picos (outliers) en las columnas num√©ricas seleccionadas\n",
        "# Se utiliza la funci√≥n calcular_IQR, que aplica el m√©todo del rango intercuart√≠lico (IQR)\n",
        "# para detectar valores fuera del rango t√≠pico en cada columna especificada\n",
        "outliers = calcular_IQR(muestra_imp,['Precipitation(in)','Temperature(F)','Humidity(%)','Visibility(mi)','Wind_Speed(mph)'])\n",
        "outliers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "nL90UIDBxvvf",
        "outputId": "1738daf8-e335-4bc4-e52d-a2c8735ed40e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    IQR  L√≠mite Inf.  L√≠mite Sup.\n",
              "Columna                                          \n",
              "Precipitation(in)   0.0          0.0          0.0\n",
              "Temperature(F)     31.0         -4.5        119.5\n",
              "Humidity(%)        30.0         17.0        137.0\n",
              "Visibility(mi)      7.0         -7.5         20.5\n",
              "Wind_Speed(mph)     8.0         -7.0         25.0"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IQR</th>\n",
              "      <th>L√≠mite Inf.</th>\n",
              "      <th>L√≠mite Sup.</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Columna</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Precipitation(in)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Temperature(F)</th>\n",
              "      <td>31.0</td>\n",
              "      <td>-4.5</td>\n",
              "      <td>119.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Humidity(%)</th>\n",
              "      <td>30.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>137.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Visibility(mi)</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-7.5</td>\n",
              "      <td>20.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wind_Speed(mph)</th>\n",
              "      <td>8.0</td>\n",
              "      <td>-7.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in outliers.iterrows():\n",
        "    columna = index\n",
        "    limite_inf = row[\"L√≠mite Inf.\"]\n",
        "    limite_sup = row[\"L√≠mite Sup.\"]\n",
        "\n",
        "    columnas_IQR = f\"`{columna}`\"\n",
        "\n",
        "    # Aplicar una transformaci√≥n a la columna para reemplazar valores at√≠picos\n",
        "    # Si un valor est√° fuera de los l√≠mites establecidos, se sustituye por el promedio de la columna\n",
        "    # En caso contrario, se conserva el valor original\n",
        "    muestra_imp = muestra_imp.withColumn(columna, when((col(columna) < limite_inf) | (col(columna) > limite_sup), muestra_imp.selectExpr(f\"avg({columnas_IQR})\").collect()[0][0])\n",
        "        .otherwise(col(columna))\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Ik_Vc3ihHYhz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se vuelve a calcular el rango intercuart√≠lico (IQR) para verificar cambios\n",
        "outliers = calcular_IQR(muestra_imp,['Precipitation(in)','Temperature(F)','Humidity(%)','Visibility(mi)','Wind_Speed(mph)'])\n",
        "outliers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "h75AazMxJ8Li",
        "outputId": "9034592d-fa61-4567-f1d2-84b758931dd6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    IQR  L√≠mite Inf.  L√≠mite Sup.\n",
              "Columna                                          \n",
              "Precipitation(in)   0.0         0.00         0.00\n",
              "Temperature(F)     31.0        -4.50       119.50\n",
              "Humidity(%)        29.0        19.50       135.50\n",
              "Visibility(mi)      7.0        -7.50        20.50\n",
              "Wind_Speed(mph)     7.7        -6.55        24.25"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IQR</th>\n",
              "      <th>L√≠mite Inf.</th>\n",
              "      <th>L√≠mite Sup.</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Columna</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Precipitation(in)</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Temperature(F)</th>\n",
              "      <td>31.0</td>\n",
              "      <td>-4.50</td>\n",
              "      <td>119.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Humidity(%)</th>\n",
              "      <td>29.0</td>\n",
              "      <td>19.50</td>\n",
              "      <td>135.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Visibility(mi)</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-7.50</td>\n",
              "      <td>20.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wind_Speed(mph)</th>\n",
              "      <td>7.7</td>\n",
              "      <td>-6.55</td>\n",
              "      <td>24.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparaci√≥n del conjunto de entrenamiento y prueba"
      ],
      "metadata": {
        "id": "bkIQuXvbbTv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categoricas = [\"Weather_Condition\", \"City\", \"State\", \"Sunrise_Sunset\",\"Wind_Direction\"]\n",
        "binarias = [\"Crossing\", \"Junction\", \"Railway\", \"Roundabout\", \"Stop\", \"Traffic_Calming\", \"Traffic_Signal\"]"
      ],
      "metadata": {
        "id": "HKTLf48hbs_d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Crear una copia de imp_sev_1 para trabajar sobre ella sin modificar el original\n",
        "Transf_muestra = muestra_imp.alias(\"copia_muestra\")\n",
        "\n",
        "# üîÑ Convertir variables binarias a formato num√©rico (0 y 1)\n",
        "for columna in binarias:\n",
        "    Transf_muestra = Transf_muestra.withColumn(columna + \"_num\", col(columna).cast(\"int\"))\n",
        "\n",
        "# üé≠ Aplicar StringIndexer a las variables categ√≥ricas para convertirlas en valores num√©ricos indexados\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col + \"_Index\").fit(Transf_muestra) for col in categoricas]\n",
        "for indexer in indexers:\n",
        "    Transf_muestra = indexer.transform(Transf_muestra)\n",
        "\n",
        "# üè∑Ô∏è Aplicar StringIndexer a las etiquetas\n",
        "index_label = StringIndexer(inputCol=\"Severity\", outputCol=\"Severity_Index\").fit(Transf_muestra)\n",
        "Transf_muestra = index_label.transform(Transf_muestra)\n",
        "\n",
        "# üèóÔ∏è Aplicar One-Hot Encoding a las variables categ√≥ricas para representarlas como vectores binarios\n",
        "codificadores = [OneHotEncoder(inputCol=col + \"_Index\", outputCol=col + \"_OHE\").fit(Transf_muestra) for col in categoricas]\n",
        "for codificador in codificadores:\n",
        "    Transf_muestra = codificador.transform(Transf_muestra)\n",
        "\n",
        "# üî• Eliminar las columnas originales que ya no se usar√°n en el modelo despu√©s de la transformaci√≥n\n",
        "Transf_muestra = Transf_muestra.drop(*categoricas).drop(*binarias)\n",
        "\n",
        "# üëÄ Mostrar el DataFrame transformado para verificar los cambios\n",
        "Transf_muestra.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX_PoP6Nh3Bj",
        "outputId": "1a0da203-a55c-4ed4-99b6-bc9ad7a904dc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+--------+--------------+-----------+--------------+---------------+------------+------------+-----------+--------------+--------+-------------------+------------------+-----------------------+----------+-----------+--------------------+--------------------+--------------+---------------------+-------------------+---------------+------------------+------------------+\n",
            "|       ID|Precipitation(in)|Severity|Temperature(F)|Humidity(%)|Visibility(mi)|Wind_Speed(mph)|Crossing_num|Junction_num|Railway_num|Roundabout_num|Stop_num|Traffic_Calming_num|Traffic_Signal_num|Weather_Condition_Index|City_Index|State_Index|Sunrise_Sunset_Index|Wind_Direction_Index|Severity_Index|Weather_Condition_OHE|           City_OHE|      State_OHE|Sunrise_Sunset_OHE|Wind_Direction_OHE|\n",
            "+---------+-----------------+--------+--------------+-----------+--------------+---------------+------------+------------+-----------+--------------+--------+-------------------+------------------+-----------------------+----------+-----------+--------------------+--------------------+--------------+---------------------+-------------------+---------------+------------------+------------------+\n",
            "|A-4912715|              0.0|       2|          60.0|       72.0|          10.0|           12.0|           0|           0|          0|             0|       0|                  0|                 0|                    1.0|    3473.0|       20.0|                 0.0|                 4.0|           0.0|       (36,[1],[1.0])|(7733,[3473],[1.0])|(48,[20],[1.0])|     (1,[0],[1.0])|    (23,[4],[1.0])|\n",
            "|A-4035789|              0.0|       2|          72.0|       20.0|          10.0|            0.0|           0|           0|          0|             0|       0|                  0|                 0|                    1.0|     330.0|       19.0|                 0.0|                 0.0|           0.0|       (36,[1],[1.0])| (7733,[330],[1.0])|(48,[19],[1.0])|     (1,[0],[1.0])|    (23,[0],[1.0])|\n",
            "|A-5298999|              0.0|       2|          75.0|       94.0|           7.0|            3.0|           0|           0|          0|             0|       0|                  0|                 0|                    1.0|    1631.0|        7.0|                 0.0|                 1.0|           0.0|       (36,[1],[1.0])|(7733,[1631],[1.0])| (48,[7],[1.0])|     (1,[0],[1.0])|    (23,[1],[1.0])|\n",
            "|A-3885258|              0.0|       2|          54.0|       78.0|          10.0|            0.0|           0|           0|          0|             0|       0|                  0|                 0|                    1.0|      61.0|        5.0|                 1.0|                 0.0|           0.0|       (36,[1],[1.0])|  (7733,[61],[1.0])| (48,[5],[1.0])|         (1,[],[])|    (23,[0],[1.0])|\n",
            "|A-6886081|              0.0|       2|          60.0|       55.0|          10.0|            6.0|           0|           0|          0|             0|       0|                  0|                 0|                    1.0|     772.0|        0.0|                 1.0|                 4.0|           0.0|       (36,[1],[1.0])| (7733,[772],[1.0])| (48,[0],[1.0])|         (1,[],[])|    (23,[4],[1.0])|\n",
            "+---------+-----------------+--------+--------------+-----------+--------------+---------------+------------+------------+-----------+--------------+--------+-------------------+------------------+-----------------------+----------+-----------+--------------------+--------------------+--------------+---------------------+-------------------+---------------+------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Definici√≥n de la lista de atributos que ser√°n utilizados en el modelo de an√°lisis\n",
        "atributos = [ 'Precipitation(in)', 'Temperature(F)', 'Humidity(%)', 'Visibility(mi)',\n",
        "              'Wind_Speed(mph)','Crossing_num', 'Junction_num', 'Railway_num',\n",
        "              'Roundabout_num','Stop_num','Traffic_Calming_num', 'Traffic_Signal_num',\n",
        "              'Weather_Condition_OHE','City_OHE','State_OHE','Sunrise_Sunset_OHE','Wind_Direction_OHE']"
      ],
      "metadata": {
        "id": "0Ya5tV_N7Wz8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üèóÔ∏è Construcci√≥n de un vector de caracter√≠sticas a partir de las variables seleccionadas\n",
        "# Se utiliza VectorAssembler para combinar m√∫ltiples columnas en una √∫nica columna de caracter√≠sticas\n",
        "assembler = VectorAssembler(inputCols=atributos, outputCol = 'Caracteristicas')\n",
        "df_vec = assembler.transform(Transf_muestra)\n",
        "\n",
        "df_vec.select('Caracteristicas','Severity_index').show(5,truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-PbBSmym4J8",
        "outputId": "f6e5e02d-53f0-41dc-d02c-ef575a4fded5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------+--------------+\n",
            "|Caracteristicas                                                                  |Severity_index|\n",
            "+---------------------------------------------------------------------------------+--------------+\n",
            "|(7853,[1,2,3,4,13,3521,7801,7829,7834],[60.0,72.0,10.0,12.0,1.0,1.0,1.0,1.0,1.0])|0.0           |\n",
            "|(7853,[1,2,3,13,378,7800,7829,7830],[72.0,20.0,10.0,1.0,1.0,1.0,1.0,1.0])        |0.0           |\n",
            "|(7853,[1,2,3,4,13,1679,7788,7829,7831],[75.0,94.0,7.0,3.0,1.0,1.0,1.0,1.0,1.0])  |0.0           |\n",
            "|(7853,[1,2,3,13,109,7786,7830],[54.0,78.0,10.0,1.0,1.0,1.0,1.0])                 |0.0           |\n",
            "|(7853,[1,2,3,4,13,820,7781,7834],[60.0,55.0,10.0,6.0,1.0,1.0,1.0,1.0])           |0.0           |\n",
            "+---------------------------------------------------------------------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìè Aplicar StandardScaler para normalizar las caracter√≠sticas\n",
        "# StandardScaler escala las caracter√≠sticas para que tengan una desviaci√≥n est√°ndar unitaria\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"Caracteristicas\", outputCol=\"Caracteristicas_scale\", withStd=True, withMean=True)\n",
        "scaler_model = scaler.fit(df_vec)\n",
        "df_scaled = scaler_model.transform(df_vec)\n",
        "df_scaled.select('Caracteristicas_scale','Severity_index').show(5,truncate = True)"
      ],
      "metadata": {
        "id": "vVS6yqRlO21R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0670d25-bf26-4071-c184-9c57bc9e52ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+--------------+\n",
            "|Caracteristicas_scale|Severity_index|\n",
            "+---------------------+--------------+\n",
            "| [-0.3713612229363...|           0.0|\n",
            "| [-0.3713612229363...|           0.0|\n",
            "| [-0.3713612229363...|           0.0|\n",
            "| [-0.3713612229363...|           0.0|\n",
            "| [-0.3713612229363...|           0.0|\n",
            "+---------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Divisi√≥n del conjunto de datos escalado en entrenamiento y prueba\n",
        "# Se asigna el 80% de los datos a train y el 20% a test, utilizando una semilla para reproducibilidad\n",
        "train, test = df_scaled.randomSplit([0.8,0.2], seed = 10)\n",
        "\n",
        "train_size = train.count()\n",
        "test_size = test.count()\n",
        "total_size = train_size + test_size\n",
        "\n",
        "# üìà C√°lculo de los porcentajes de cada conjunto respecto al total de datos\n",
        "train_pct = (train_size / total_size) * 100\n",
        "test_pct = (test_size / total_size) * 100\n",
        "\n",
        "# üì¢ Impresi√≥n de la distribuci√≥n de datos en los conjuntos de entrenamiento y prueba\n",
        "print(f\"\"\"Existen \\033[36m{train_size:,}\\033[0m instancias en el conjunto de entrenamiento ({train_pct:.2f}%),\n",
        "y \\033[36m{test_size:,}\\033[0m en el conjunto de prueba ({test_pct:.2f}%).\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSgGyGFgCk9M",
        "outputId": "e99bdd27-518e-4628-f0d5-3a77c7d46c7e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existen \u001b[36m118,446\u001b[0m instancias en el conjunto de entrenamiento (80.03%),\n",
            "y \u001b[36m29,554\u001b[0m en el conjunto de prueba (19.97%).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construcci√≥n del modelo de aprendizaje supervisado"
      ],
      "metadata": {
        "id": "_mGrG9SVeex-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìâ Definir el modelo de regresi√≥n lineal\n",
        "# Se especifican las caracter√≠sticas de entrada y la variable objetivo\n",
        "# Se configuran hiperpar√°metros como el n√∫mero de iteraciones, la regularizaci√≥n y ElasticNet\n",
        "lr = LinearRegression(featuresCol='Caracteristicas_scale', labelCol='Severity_Index', maxIter=300, regParam=0.1, elasticNetParam=0.8)\n",
        "\n",
        "# üèãÔ∏è Entrenamiento del modelo de regresi√≥n lineal con el conjunto de datos de entrenamiento\n",
        "lr_model = lr.fit(train)\n",
        "\n",
        "# üîÑ Generaci√≥n de predicciones en el conjunto de prueba\n",
        "y_pred = lr_model.transform(test)\n",
        "\n",
        "# üëÄ Visualizaci√≥n de los primeros 5 resultados con las caracter√≠sticas escaladas, el √≠ndice real y la predicci√≥n\n",
        "y_pred.select('Caracteristicas_scale','Severity_Index','prediction').show(5,truncate = True)"
      ],
      "metadata": {
        "id": "GN9E6EYYoHLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb7ca49-5c0c-49e1-ccb4-81a92ffe2946"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+--------------+------------------+\n",
            "|Caracteristicas_scale|Severity_Index|        prediction|\n",
            "+---------------------+--------------+------------------+\n",
            "| [-0.3713612229363...|           0.0|1.1670775015564125|\n",
            "| [-0.3713612229363...|           0.0|1.1643756618806025|\n",
            "| [-0.3713612229363...|           0.0|0.6519426483175073|\n",
            "| [-0.3713612229363...|           0.0|1.1700204822651412|\n",
            "| [-0.3713612229363...|           0.0| 1.170454801151175|\n",
            "+---------------------+--------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Imprimir los coeficientes del modelo\n",
        "# Estos valores representan el peso asignado a cada caracter√≠stica en la ecuaci√≥n de regresi√≥n lineal\n",
        "print (f'El coeficiente del modelo : {lr_model.coefficients}')\n",
        "\n",
        "# üéØ Imprimir el intercepto del modelo\n",
        "# Este valor indica el punto donde la l√≠nea de regresi√≥n cruza el eje vertical cuando todas las caracter√≠sticas son cero\n",
        "print (f'El intercepto del modelo es : {lr_model.intercept}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHZ-ACWLoNww",
        "outputId": "65101db3-d08a-4d22-d275-e9d06b89a129"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El coeficiente del modelo : (7853,[3,4,12,13,14,15,16],[0.0072260203273301835,-0.0042370892576847705,0.11366886636089815,0.11642096993137069,0.1153523295316653,0.11545001126048281,0.11314114694150355])\n",
            "El intercepto del modelo es : 0.7847284369666645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìè Creaci√≥n del evaluador de regresi√≥n\n",
        "# Se utiliza para calcular m√∫ltiples m√©tricas de desempe√±o del modelo de regresi√≥n lineal\n",
        "eval_lr = RegressionEvaluator(\n",
        "    labelCol=\"Stop_num\",\n",
        "    predictionCol=\"prediction\"\n",
        ")\n",
        "\n",
        "# üìâ C√°lculo del Error Cuadr√°tico Medio (RMSE)\n",
        "# Indica la magnitud promedio del error del modelo, penalizando grandes desviaciones\n",
        "rmse_lr = eval_lr.evaluate(y_pred, {eval_lr.metricName: \"rmse\"})\n",
        "\n",
        "# üîÑ C√°lculo del Error Medio Cuadr√°tico (MSE)\n",
        "# Mide la diferencia cuadr√°tica entre los valores reales y predichos (m√°s sensible a errores grandes)\n",
        "mse_lr = eval_lr.evaluate(y_pred, {eval_lr.metricName: \"mse\"})\n",
        "\n",
        "# üìä C√°lculo del Error Absoluto Medio (MAE)\n",
        "# Eval√∫a la precisi√≥n del modelo al calcular el error promedio absoluto sin penalizaci√≥n cuadr√°tica\n",
        "mae_lr = eval_lr.evaluate(y_pred, {eval_lr.metricName: \"mae\"})\n",
        "\n",
        "# üéØ C√°lculo del coeficiente de determinaci√≥n (R¬≤)\n",
        "# Mide qu√© proporci√≥n de la variabilidad en los datos es explicada por el modelo\n",
        "r2_lr = eval_lr.evaluate(y_pred, {eval_lr.metricName: \"r2\"})\n",
        "\n",
        "print(f\"Regresi√≥n Lineal RMSE: {rmse_lr:.3f}\")\n",
        "print(f\"Regresi√≥n Lineal MSE: {mse_lr:.3f}\")\n",
        "print(f\"Regresi√≥n Lineal MAE: {mae_lr:.3f}\")\n",
        "print(f\"Regresi√≥n Lineal R¬≤: {r2_lr:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bayuh7qYXD0n",
        "outputId": "31d34b46-0684-4405-8b8e-c61391dff9cd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresi√≥n Lineal RMSE: 0.809\n",
            "Regresi√≥n Lineal MSE: 0.655\n",
            "Regresi√≥n Lineal MAE: 0.774\n",
            "Regresi√≥n Lineal R¬≤: -29.810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Stage 14614:=========================================>             (6 + 2) / 8]\r\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El modelo tiene un rendimiento bajo, ya que su valor de R¬≤ es negativo. Esto significa que no se ajusta bien a los datos y no logra encontrar patrones √∫tiles. Para mejorar su precisi√≥n, se podr√≠a revisar qu√© caracter√≠sticas est√°n siendo usadas o probar un modelo diferente que funcione mejor para este problema."
      ],
      "metadata": {
        "id": "g6vgt3yjXhPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üå≥ Definir el modelo de Random Forest Regressor\n",
        "# Este modelo utiliza m√∫ltiples √°rboles de decisi√≥n para mejorar la precisi√≥n de las predicciones\n",
        "rf = RandomForestRegressor(\n",
        "    featuresCol='Caracteristicas_scale',\n",
        "    labelCol='Severity_Index',\n",
        "    numTrees=100,\n",
        "    maxDepth=10,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# üèãÔ∏è Entrenar el modelo con el conjunto de entrenamiento\n",
        "rf_model = rf.fit(train)\n",
        "\n",
        "# üîÑ Generar predicciones con el conjunto de prueba\n",
        "y_pred_rf = rf_model.transform(test)\n",
        "\n",
        "# üìè Evaluador de regresi√≥n para medir el rendimiento del modelo\n",
        "eval_rf = RegressionEvaluator(labelCol=\"Severity_Index\", predictionCol=\"prediction\")\n",
        "\n",
        "rmse_rf = eval_rf.evaluate(y_pred_rf, {eval_rf.metricName: \"rmse\"})\n",
        "mse_rf = eval_rf.evaluate(y_pred_rf, {eval_rf.metricName: \"mse\"})\n",
        "mae_rf = eval_rf.evaluate(y_pred_rf, {eval_rf.metricName: \"mae\"})\n",
        "r2_rf = eval_rf.evaluate(y_pred_rf, {eval_rf.metricName: \"r2\"})\n",
        "\n",
        "print(f\"Random Forest RMSE: {rmse_rf:.3f}\")\n",
        "print(f\"Random Forest MSE: {mse_rf:.3f}\")\n",
        "print(f\"Random Forest MAE: {mae_rf:.3f}\")\n",
        "print(f\"Random Forest R¬≤: {r2_rf:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96FigUpiZRv-",
        "outputId": "57bc529d-2212-426c-83b3-a76d64e2f96c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest RMSE: 0.744\n",
            "Random Forest MSE: 0.554\n",
            "Random Forest MAE: 0.626\n",
            "Random Forest R¬≤: 0.357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos resultados muestran que el modelo de Random Forest ha logrado una mejora significativa en comparaci√≥n con el de regresi√≥n lineal, ofreciendo una mayor precisi√≥n en las predicciones. Aunque el R¬≤ sigue siendo relativamente bajo, indica que el modelo est√° capturando patrones √∫tiles en los datos."
      ],
      "metadata": {
        "id": "oa0D9iTmd6kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construcci√≥n del modelo de aprendizaje no supervisado"
      ],
      "metadata": {
        "id": "4pQdlVj9ei68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üîç Definir el modelo K-Means\n",
        "# K-Means es un algoritmo de agrupamiento que clasifica los datos en k grupos seg√∫n su similitud\n",
        "kmeans = KMeans(\n",
        "    featuresCol='Caracteristicas_scale',\n",
        "    k=5,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# üèãÔ∏è Entrenar el modelo con los datos escalados\n",
        "model_kmeans = kmeans.fit(df_scaled)\n",
        "\n",
        "# üîÑ Aplicar el modelo entrenado para hacer predicciones y asignar cada dato a un cluster\n",
        "kMeans_pred = model_kmeans.transform(df_scaled)\n",
        "\n",
        "# üìä Mostrar los resultados de la agrupaci√≥n\n",
        "kMeans_pred.select('Caracteristicas_scale','Severity_Index','prediction').show(5,truncate = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CQbfcmkgbQU",
        "outputId": "53b7688e-9426-4330-b12a-04253a169ff7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+--------------+----------+\n",
            "|Caracteristicas_scale|Severity_Index|prediction|\n",
            "+---------------------+--------------+----------+\n",
            "| [-0.3713612229363...|           0.0|         0|\n",
            "| [-0.3713612229363...|           0.0|         0|\n",
            "| [-0.3713612229363...|           0.0|         0|\n",
            "| [-0.3713612229363...|           0.0|         0|\n",
            "| [-0.3713612229363...|           0.0|         0|\n",
            "+---------------------+--------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üìè Definir el evaluador de clustering\n",
        "# Se utiliza para medir qu√© tan bien separados est√°n los clusters generados por K-Means\n",
        "eval = ClusteringEvaluator(featuresCol='Caracteristicas_scale', predictionCol='prediction', metricName=\"silhouette\")\n",
        "\n",
        "# üîç Calcular el Silhouette Score\n",
        "# Esta m√©trica eval√∫a qu√© tan bien definidos est√°n los clusters. Valores cercanos a 1 indican buenos clusters,\n",
        "# valores cercanos a 0 sugieren solapamiento y valores negativos indican mala asignaci√≥n de datos\n",
        "silhouette_score = eval.evaluate(kMeans_pred)\n",
        "\n",
        "print(f\"Silhouette Score: {silhouette_score:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5mDttnpcLc9",
        "outputId": "752b20c1-50da-4ab2-cb94-be0ecc841d4b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Score: -0.432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Stage 18555:================================================>      (7 + 1) / 8]\r\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kMeans_pred.groupBy('prediction').count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jar04XQ3l0g1",
        "outputId": "d031ba70-c603-4e19-abcd-904afdbd3df8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Stage 18706:>                                                      (0 + 8) / 8]\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+\n",
            "|prediction| count|\n",
            "+----------+------+\n",
            "|         1|  4073|\n",
            "|         3|    10|\n",
            "|         2|    49|\n",
            "|         0|143853|\n",
            "|         4|    15|\n",
            "+----------+------+\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r                                                                                \r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El resultado del Silhouette Score muestra que los grupos creados por K-Means no est√°n bien separados. Esto significa que el modelo no est√° organizando los datos correctamente y que muchos puntos est√°n m√°s cerca de otro grupo distinto al que se les asign√≥. Como el Silhouette Score es negativo, indica que la agrupaci√≥n no est√° funcionando bien y que podr√≠a necesitar ajustes."
      ],
      "metadata": {
        "id": "CKR48cB0mIk1"
      }
    }
  ]
}